{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPC2N7wkIlfUtSMnuv8+Kd0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Padmasri-Nambi/GENERATIVE-AI-PROJECTS/blob/main/notes_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUTYde4wEZQv",
        "outputId": "66d4168b-4c8c-4887-a70e-2bb0ab2f905b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.24.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "notes_generator=pipeline('text-generation',model='gpt2')\n",
        "chapter=input(\"enter chapter name:\")\n",
        "\n",
        "prompt_notes = f\"\"\"\n",
        "write detailed study notes for {chapter}\n",
        "include explanation, example and key points\n",
        "\"\"\"\n",
        "detailed_notes=notes_generator(\n",
        "    prompt_notes,\n",
        "    max_length=300,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "print(detailed_notes[0]['generated_text'])\n",
        "\n",
        "prompt_summary = f\"\"\"\n",
        "summarize the chapter: {chapter} in one page\n",
        "\"\"\"\n",
        "summary=notes_generator(\n",
        "    prompt_summary,\n",
        "    max_length=200,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "print(\"\\n one-page summary \\n\")\n",
        "print(summary[0]['generated_text'])\n",
        "\n",
        "prompt_definition=f\"\"\"\n",
        "list important definitions and formulas from the chapter:{chapter}\n",
        "use bullet points\n",
        "\"\"\"\n",
        "definitions=notes_generator(\n",
        "    prompt_definition,\n",
        "    max_length=200,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "print(\"\\n definitions and formulas:\")\n",
        "print(definitions[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
        "id": "CI6XCWvEJ8nz",
        "outputId": "f6647035-250c-4a85-dd1d-1f074df07d9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff947ee17f894958a3cc4bc5c534a1a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "062415ead2a940689dc8886323d9ff50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eceabb580cb849338619a7c3e919ac34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d607d7994cf445dd9e2cffe0471ab669"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e978caf54e2140dd9cbffb5efb0583f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "675ea74ac5064f54aec7db06566837ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79f254639a404e11ae52d94164f35586"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bcf671a2416460d91240fb6fbb00c3e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter chapter name:90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing `generation_config` together with generation-related arguments=({'num_return_sequences', 'max_length'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=300) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "write detailed study notes for 90\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points write detailed study notes for 90 include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n",
            "include explanation, example and key points\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " one-page summary \n",
            "\n",
            "\n",
            "summarize the chapter: 90 in one page\n",
            "\n",
            "Chapter 1: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 2: \"Gangnam Style\" by the two of them\n",
            "\n",
            "Chapter 3: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 4: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 5: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 6: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 7: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 8: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 9: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 10: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 11: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 12: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 13: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 14: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 15: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 16: \"Bondage\" by the two of them\n",
            "\n",
            "Chapter 17: \"Bondage\" by the two of them\n",
            "\n",
            "\n",
            " definitions and formulas:\n",
            "\n",
            "list important definitions and formulas from the chapter:90\n",
            "use bullet points\n",
            "use bullet points to explain common problems with the definition\n",
            "use bullet points to list common problems with the definition\n",
            "use bullet points to explain common problems with the definition using bullet points to list common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to describe common problems with the definition using bullet points to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DI-YmsxtP1Ih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
